{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Random Forest model\n",
    "\n",
    "Our previous work has all been based on logistic regression, which is the most common 'standard model' against which all other models are compared.\n",
    "\n",
    "In this notebook we swap out the logistic regression model for a Random Forest model. Random Forests are often chosen for classification based on structured data (i.e. when we have specific features of data, rather than unstructured data like a picture or a sound file).\n",
    "\n",
    "Random Forests are based on constructing multiple decision trees, each of which sees only part of the data for each case, and only has limited ‘branches’. Random Forests tend to be less prone to over-fitting than decision trees. For more on the basis of Random Forests see:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Random_forest\n",
    "\n",
    "Note in this example how similar the code is to our previous logistic regression model. A couple of notable changes are:\n",
    "\n",
    "* Data for Random Forest models do not need standardisation; we use the raw data.\n",
    "* Rather than having coefficients, we output model ‘importances’ which reflect how influential a feature is in deciding classification. This is accessed through examining `model.feature_importances_`.\n",
    "\n",
    "Here we will again use stratified K-fold validation to test the model performance. We will use default settings for the Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Run the following code if data for Titanic survival has not been previously downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = False\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data & drop passenger ID\n",
    "data = pd.read_csv('data/processed_data.csv')\n",
    "\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "\n",
    "# Split data into two DataFrames\n",
    "X_df = data.drop('Survived',axis=1)\n",
    "y_df = data['Survived']\n",
    "\n",
    "# Convert DataFrames to NumPy arrays\n",
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred_test == y_test)\n",
    "print (f'Accuracy: {accuracy:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\n",
    "        \"classifier\", [\"LogReg\", \"RandomForest\"])\n",
    "\n",
    "    # Step 2. Setup values for the hyperparameters:\n",
    "    if classifier_name == 'LogReg':\n",
    "        logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "        classifier_obj = linear_model.LogisticRegression(C=logreg_c)\n",
    "    else:\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 1000)\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = ensemble.RandomForestClassifier(\n",
    "            max_depth=rf_max_depth, n_estimators=rf_n_estimators\n",
    "        )\n",
    "    \n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 4: Running it\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      "0.8226711560044894\n",
      "The best parameters are : \n",
      "{'classifier': 'RandomForest', 'rf_n_estimators': 224, 'rf_max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best value is : \\n{study.best_value}\")\n",
    "\n",
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\n",
    "        \"classifier\", [\"LogReg\", \"RandomForest\"])\n",
    "\n",
    "    # Step 2. Setup values for the hyperparameters:\n",
    "    if classifier_name == 'LogReg':\n",
    "        logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "        classifier_obj = linear_model.LogisticRegression(C=logreg_c)\n",
    "    else:\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 1000)\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = ensemble.RandomForestClassifier(\n",
    "            max_depth=rf_max_depth, n_estimators=rf_n_estimators\n",
    "        )\n",
    "    \n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X, y, n_jobs=-1, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 4: Running it\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
