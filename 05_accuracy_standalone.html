
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Accuracy measurements in machine learning &#8212; Titanic Survival Machine Learning</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Application of alternative accuracy measurements to a logistic regression model" href="06_accuracy_logistic_regression.html" />
    <link rel="prev" title="Avoiding over-fitting with regularisation" href="04_regularisation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      <h1 class="site-logo" id="site-title">Titanic Survival Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="front_page.html">
   Titanic Survival
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Setting up an environment file to run these notebooks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="setup.html">
   Setting up an environment
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data preprocessing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_preprocessing.html">
   Kaggle Titanic survival - data preprocessing
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Basic methods
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="02_logistic_regression.html">
   Logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_k_fold.html">
   Measuring model accuracy with K-fold stratification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_regularisation.html">
   Avoiding over-fitting with regularisation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Accuracy measurements in machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_accuracy_logistic_regression.html">
   Application of alternative accuracy measurements to a logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_learning_curve.html">
   Learning curves - how much data do we need?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_roc.html">
   Receiver Operator Characteristic (ROC) curve
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Feature selection and expansion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09_feature_selection_1_univariate.html">
   Feature selection using univariate statistical selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_feature_selection_2_forward.html">
   Feature selection using forward selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_feature_selection_3_backward.html">
   Feature selection using backward elimination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feature_expansion.html">
   Feature expansion
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Working with imbalanced data sets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13_imbalanced%20_data_weighting.html">
   Dealing with imbalanced data by model weighting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_imbalanced%20_data_sampling.html">
   Dealing with imbalanced data by under or over sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_imbalanced%20_data_threshold.html">
   Dealing with imbalanced data by changing classification cut-off levels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_imbalanced%20_data_smote.html">
   Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Random forest model
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17_random_forest.html">
   A Random Forest model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_random_forest_roc.html">
   Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  TensorFlow neural nets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="19_tensorflow_1.html">
   TensorFlow neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_tensorflow_api.html">
   TensorFlow api-based neural net.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_tensorflow_roc.html">
   TensorFlow Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_tensorflow_deep_wide.html">
   TensorFlow ‘Wide and Deep’ neural nets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25_tensorflow_bagging.html">
   TensorFlow Bagging
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="50_check_calibration.html">
   Checking model calibration
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/05_accuracy_standalone.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/MichaelAllen1966/titanic/blob/main//github/executablebooks/jupyter-book/blob/master/05_accuracy_standalone.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-function">
   Define function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demonstrate-method">
   Demonstrate method
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="accuracy-measurements-in-machine-learning">
<h1>Accuracy measurements in machine learning<a class="headerlink" href="#accuracy-measurements-in-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>The most common measurement in machine learning is ‘accuracy, that is the proportion of cases where the classification is correct. This may at times not be the best measurement. For example, imagine you wish to detect who is carrying the back death among people coming through an airport, by measuring a range of features (such as body temperature, or the presence of a particular skin rash pattern). Now imagine that one in a thousand people are carriers of black death, who if allowed through will start off a major epidemic. We may then optimise a machine learning algorithm and it reports 99.9% accuracy. Impressive! Or is it? The algorithm may have simply classed everybody as not having black death. It will be right 999 times out of 1,000. But at the same time it will miss every single case of black death that you intended to detect. This is an extreme example of where we need more sophisticated measurements of accuracy. In this particular case, we probably want to measure sensitivity and specificity. Sensitivity measures the proportion of positive cases (black death) correctly classified, while specificity measures the proportion of negative cases (no black death) correctly classified. We will later see how we might change machine learning thresholds to adjust the balance between sensitivity and specificity.</p>
<p>Sensitivity and specificity are not the only measures (though they are common in health diagnosis problems). Below are a range of measures that our function will calculated (given the observed and predicted class values of a range of cases). In addition to sensitivity and specificity, common measures used in machine learning are precision, recall and f1 (a combination of precision and recall).</p>
<p>The full list of measures that our function will return (in the form of a dictionary) is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> 1) observed positive rate: proportion of observed cases that are +ve
 2) predicted positive rate: proportion of predicted cases that are +ve
 3) observed negative rate: proportion of observed cases that are -ve
 4) predicted negative rate: proportion of predicted cases that are -ve  
 5) accuracy: proportion of predicted results that are correct    
 6) precision: proportion of predicted +ve that are correct
 7) recall: proportion of true +ve correctly identified
 8) f1: harmonic mean of precision and recall
 9) sensitivity: Same as recall
10) specificity: Proportion of true -ve identified:        
11) positive likelihood: increased probability of true +ve if test +ve
12) negative likelihood: reduced probability of true +ve if test -ve
13) false positive rate: proportion of false +ves in true -ve patients
14) false negative rate: proportion of false -ves in true +ve patients
15) true positive rate: Same as recall
16) true negative rate
17) positive predictive value: chance of true +ve if test +ve
18) negative predictive value: chance of true -ve if test -ve
</pre></div>
</div>
<p>Please note that these measures are for a ‘binomial’ classification problem. That is where there are two alternatives for each case (e.g. survived or not-survived on the Titanic). Where there are more than two possible classes, a confusion matrix is most commonly used (e.g. see <a class="reference external" href="https://pythonhealthcare.org/2018/04/21/77-machine-learning-visualising-accuracy-and-error-in-a-classification-model-with-a-confusion-matrix/">https://pythonhealthcare.org/2018/04/21/77-machine-learning-visualising-accuracy-and-error-in-a-classification-model-with-a-confusion-matrix/</a>)</p>
<div class="section" id="define-function">
<h2>Define function<a class="headerlink" href="#define-function" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates a range of accuracy scores from observed and predicted classes.</span>
<span class="sd">    </span>
<span class="sd">    Takes two list or NumPy arrays (observed class values, and predicted class </span>
<span class="sd">    values), and returns a dictionary of results.</span>
<span class="sd">    </span>
<span class="sd">     1) observed positive rate: proportion of observed cases that are +ve</span>
<span class="sd">     2) Predicted positive rate: proportion of predicted cases that are +ve</span>
<span class="sd">     3) observed negative rate: proportion of observed cases that are -ve</span>
<span class="sd">     4) Predicted negative rate: proportion of predicted cases that are -ve  </span>
<span class="sd">     5) accuracy: proportion of predicted results that are correct    </span>
<span class="sd">     6) precision: proportion of predicted +ve that are correct</span>
<span class="sd">     7) recall: proportion of true +ve correctly identified</span>
<span class="sd">     8) f1: harmonic mean of precision and recall</span>
<span class="sd">     9) sensitivity: Same as recall</span>
<span class="sd">    10) specificity: Proportion of true -ve identified:        </span>
<span class="sd">    11) positive likelihood: increased probability of true +ve if test +ve</span>
<span class="sd">    12) negative likelihood: reduced probability of true +ve if test -ve</span>
<span class="sd">    13) false positive rate: proportion of false +ves in true -ve patients</span>
<span class="sd">    14) false negative rate: proportion of false -ves in true +ve patients</span>
<span class="sd">    15) true positive rate: Same as recall</span>
<span class="sd">    16) true negative rate</span>
<span class="sd">    17) positive predictive value: chance of true +ve if test +ve</span>
<span class="sd">    18) negative predictive value: chance of true -ve if test -ve</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Converts list to NumPy arrays</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    
    <span class="c1"># Calculate accuracy scores</span>
    <span class="n">observed_positives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">observed_negatives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">predicted_positives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">predicted_negatives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="n">true_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">false_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="n">true_negatives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">observed</span><span class="p">)</span>
    
    <span class="n">precision</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span>
                 <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">false_positives</span><span class="p">)))</span>
        
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">recall</span>
    
    <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">((</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">))</span>
    
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    
    <span class="n">positive_likelihood</span> <span class="o">=</span> <span class="n">sensitivity</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span><span class="p">)</span>
    
    <span class="n">negative_likelihood</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span><span class="p">)</span> <span class="o">/</span> <span class="n">specificity</span>
    
    <span class="n">false_positive_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span>
    
    <span class="n">false_negative_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span>
    
    <span class="n">true_positive_rate</span> <span class="o">=</span> <span class="n">sensitivity</span>
    
    <span class="n">true_negative_rate</span> <span class="o">=</span> <span class="n">specificity</span>
    
    <span class="n">positive_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> 
                                 <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">))</span>
    
    <span class="n">negative_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> 
                                  <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">))</span>
    
    <span class="c1"># Create dictionary for results, and add results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">precision</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">recall</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;sensitivity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitivity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;specificity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">specificity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_predictive_value</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_predictive_value</span>
    
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="demonstrate-method">
<h2>Demonstrate method<a class="headerlink" href="#demonstrate-method" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create two lists to test function</span>
<span class="n">observed</span> <span class="o">=</span>  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Call calculate_accuracy function</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>

<span class="c1"># Print results up to three decimal places</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{0:0.3}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>observed_positive_rate 0.4
observed_negative_rate 0.6
predicted_positive_rate 0.4
predicted_negative_rate 0.6
accuracy 0.8
precision 0.75
recall 0.75
f1 0.75
sensitivity 0.75
specificity 0.833
positive_likelihood 4.5
negative_likelihood 0.3
false_positive_rate 0.167
false_negative_rate 0.25
true_positive_rate 0.75
true_negative_rate 0.833
positive_predictive_value 0.75
negative_predictive_value 1.25
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="04_regularisation.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Avoiding over-fitting with regularisation</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="06_accuracy_logistic_regression.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Application of alternative accuracy measurements to a logistic regression model</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Michael Allen<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>