
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>PyTorch simple sequential neural net &#8212; Titanic Survival Machine Learning</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="PyTorch class-based neural net" href="46_pytorch_class.html" />
    <link rel="prev" title="TensorFlow Bagging" href="25_tensorflow_bagging.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Titanic Survival Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="front_page.html">
   Titanic Survival
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Setting up an environment file to run these notebooks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="setup.html">
   Setting up an environment
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Data preprocessing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_preprocessing.html">
   Kaggle Titanic survival - data preprocessing
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Basic methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="02_logistic_regression.html">
   Logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_k_fold.html">
   Measuring model accuracy with K-fold stratification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_regularisation.html">
   Avoiding over-fitting with regularisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_accuracy_standalone.html">
   Accuracy measurements in machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_accuracy_logistic_regression.html">
   Application of alternative accuracy measurements to a logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_learning_curve.html">
   Learning curves - how much data do we need?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_roc.html">
   Receiver Operator Characteristic (ROC) curve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="50_check_calibration.html">
   Checking model calibration
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Optimising machine learning models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="40_optuna.html">
   Optimising machine learning models with Optuna
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Feature selection and expansion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09_feature_selection_1_univariate.html">
   Feature selection using univariate statistical selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_feature_selection_2_forward.html">
   Feature selection using forward selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_feature_selection_3_backward.html">
   Feature selection using backward elimination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feature_expansion.html">
   Feature expansion
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Working with imbalanced data sets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13_imbalanced%20_data_weighting.html">
   Dealing with imbalanced data by model weighting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_imbalanced%20_data_sampling.html">
   Dealing with imbalanced data by under or over sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_imbalanced%20_data_threshold.html">
   Dealing with imbalanced data by changing classification cut-off levels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_imbalanced%20_data_smote.html">
   Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Random forest model
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17_random_forest.html">
   A Random Forest model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_random_forest_roc.html">
   Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  TensorFlow neural nets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="19_tensorflow_1.html">
   TensorFlow neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_tensorflow_api.html">
   TensorFlow api-based neural net.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_tensorflow_roc.html">
   TensorFlow Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_tensorflow_deep_wide.html">
   TensorFlow ‘Wide and Deep’ neural nets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25_tensorflow_bagging.html">
   TensorFlow Bagging
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Pytorch neural nets
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   PyTorch simple sequential neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="46_pytorch_class.html">
   PyTorch class-based neural net
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Model explainability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="26_logistic_regression_shap.html">
   Explaining model predictions with Shapley values - Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="27_random_forest_shap.html">
   Explaining model predictions with Shapley values - Random Forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="28_neural_net_shap.html">
   Explaining model predictions with Shapley values - Neural Network
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Creating synthetic data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="30_synthetic_data%20_SMOTE.html">
   Creating synthetic Titanic passenger data with SMOTE
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/45_pytorch_simple.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   PyTorch simple sequential neural net
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-modules">
     Load modules
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-data-if-not-previously-downloaded">
     Download data if not previously downloaded
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-function-to-calculate-accuracy-measurements">
     Define function to calculate accuracy measurements
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-function-to-scale-data">
     Define function to scale data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-data">
     Load data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#set-up-neural-net">
   Set up neural net
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-the-model-with-k-fold-validation">
     Run the model with k-fold validation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#show-training-and-test-results">
     Show training and test results
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-results-box-plot">
     Plot results: Box Plot
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="pytorch-simple-sequential-neural-net">
<h1>PyTorch simple sequential neural net<a class="headerlink" href="#pytorch-simple-sequential-neural-net" title="Permalink to this headline">¶</a></h1>
<p>In this workbook we build a neural network to predict survival. The two common frameworks used for neural networks (as of 2020) are TensorFlow and PyTorch. Both are excellent frameworks. TensorFlow frequently requires fewer lines of code, but PyTorch is more natively Python in its syntax, and also allows for easier debugging as the model may be interrupted, with a breakpoint, and debugged as necessary. This makes PyTorch particularly suitable for research and experimentation. A disadvantage of using PyTorch is that, compared with TensorFlow, there are fewer training materials and examples available.</p>
<p>Both TensorFlow and PyTorch allow the neural network to be trained on a GPU, which is beneficial for large neural networks (especially those processing image, sound or free-text data). In order to lever the benefits of GPU (which perform many calculations simultaneously), data is grouped into batches. These batches are presented to the CPU in a single object called a Tensor (a multi-dimensional array).</p>
<p>Installation instructions for PyTorch may be found at <a class="reference external" href="http://pytorch.org">pytorch.org</a>. (If in doubt about what installation to use, use <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> and use CPU-only, not CUDA). If you are using Anaconda then it is advised to create a new environment, and install pytorch, numpy, pandas, sci-kit learn and matplotlib into that new environment. For more on Anaconda environments see: <a class="reference external" href="https://docs.anaconda.com/anaconda/navigator/tutorials/manage-environments/">https://docs.anaconda.com/anaconda/navigator/tutorials/manage-environments/</a></p>
<p>There are two versions of this workbook. This version uses a simpler form of constructing the neural network, which assumes all layers of the network occur in a simple sequence. The alternative version uses a class-based method which offers more flexibility (but at the cost of a little simplicity). It is recommended to work through both methods.</p>
<p>It is not the intention here to describe neural networks in any detail, but rather give some introductory code to using a neural network for a classification problem. For an introduction to neural networks see: <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neural_network">https://en.wikipedia.org/wiki/Artificial_neural_network</a></p>
<p>The code for PyTorch here keeps all calculations on the CPU rather than passing to a GPU (if you have one). Running neural networks on CPUs is fine for small sets of structured data such as our Titanic data. GPUs come in to their own for large data sets or unstructured data like images, sound clips, or free text.</p>
<p>The training process of a neural network consists of three general phases which are repeated across all the data. All of the data is passed through the network multiple times (the number of iterations, which may be as few as 3-5 or may be 100+). The three phases are:</p>
<ul class="simple">
<li><p>Pass training X data to the network and predict y</p></li>
<li><p>Calculate the ‘loss’ (error) between the predicted and observed (actual) values of y</p></li>
<li><p>Adjust the network a little (as defined by the learning rate) so that the error is reduced. The correction of the network is performed by PyTorch or TensorFlow using a technique called ‘back-propagation’.</p></li>
</ul>
<p>The learning is repeated until maximum accuracy is achieved (but keep an eye on accuracy of test data as well as training data as the network may develop significant over-fitting to training data unless steps are taken to offset the potential for over-fitting, such as use of ‘drop-out’ layers described below).</p>
<p>Note: Neural Networks are most often used for complex unstructured data. For structured data, other techniques, such as Random Forest,s may frequently be preferred.</p>
<section id="load-modules">
<h2>Load modules<a class="headerlink" href="#load-modules" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># General</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="c1"># pytorch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="download-data-if-not-previously-downloaded">
<h2>Download data if not previously downloaded<a class="headerlink" href="#download-data-if-not-previously-downloaded" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download_required</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">download_required</span><span class="p">:</span>
    
    <span class="c1"># Download processed data:</span>
    <span class="n">address</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/MichaelAllen1966/&#39;</span> <span class="o">+</span> \
                <span class="s1">&#39;1804_python_healthcare/master/titanic/data/processed_data.csv&#39;</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">address</span><span class="p">)</span>

    <span class="c1"># Create a data subfolder if one does not already exist</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">data_directory</span> <span class="o">=</span><span class="s1">&#39;./data/&#39;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">data_directory</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">data_directory</span><span class="p">)</span>

    <span class="c1"># Save data</span>
    <span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">data_directory</span> <span class="o">+</span> <span class="s1">&#39;processed_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-function-to-calculate-accuracy-measurements">
<h2>Define function to calculate accuracy measurements<a class="headerlink" href="#define-function-to-calculate-accuracy-measurements" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates a range of accuracy scores from observed and predicted classes.</span>
<span class="sd">    </span>
<span class="sd">    Takes two list or NumPy arrays (observed class values, and predicted class </span>
<span class="sd">    values), and returns a dictionary of results.</span>
<span class="sd">    </span>
<span class="sd">     1) observed positive rate: proportion of observed cases that are +ve</span>
<span class="sd">     2) Predicted positive rate: proportion of predicted cases that are +ve</span>
<span class="sd">     3) observed negative rate: proportion of observed cases that are -ve</span>
<span class="sd">     4) Predicted negative rate: proportion of predicted cases that are -ve  </span>
<span class="sd">     5) accuracy: proportion of predicted results that are correct    </span>
<span class="sd">     6) precision: proportion of predicted +ve that are correct</span>
<span class="sd">     7) recall: proportion of true +ve correctly identified</span>
<span class="sd">     8) f1: harmonic mean of precision and recall</span>
<span class="sd">     9) sensitivity: Same as recall</span>
<span class="sd">    10) specificity: Proportion of true -ve identified:        </span>
<span class="sd">    11) positive likelihood: increased probability of true +ve if test +ve</span>
<span class="sd">    12) negative likelihood: reduced probability of true +ve if test -ve</span>
<span class="sd">    13) false positive rate: proportion of false +ves in true -ve patients</span>
<span class="sd">    14) false negative rate: proportion of false -ves in true +ve patients</span>
<span class="sd">    15) true positive rate: Same as recall</span>
<span class="sd">    16) true negative rate: Same as specificity</span>
<span class="sd">    17) positive predictive value: chance of true +ve if test +ve</span>
<span class="sd">    18) negative predictive value: chance of true -ve if test -ve</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Converts list to NumPy arrays</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    
    <span class="c1"># Calculate accuracy scores</span>
    <span class="n">observed_positives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">observed_negatives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">predicted_positives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">predicted_negatives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="n">true_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">false_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="n">true_negatives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">false_negatives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_negatives</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">observed</span><span class="p">)</span>
    
    <span class="n">precision</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span>
                 <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">false_positives</span><span class="p">)))</span>
        
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">recall</span>
    
    <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">((</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">))</span>
    
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    
    <span class="n">positive_likelihood</span> <span class="o">=</span> <span class="n">sensitivity</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span><span class="p">)</span>
    
    <span class="n">negative_likelihood</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span><span class="p">)</span> <span class="o">/</span> <span class="n">specificity</span>
    
    <span class="n">false_positive_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span>
    
    <span class="n">false_negative_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span>
    
    <span class="n">true_positive_rate</span> <span class="o">=</span> <span class="n">sensitivity</span>
    
    <span class="n">true_negative_rate</span> <span class="o">=</span> <span class="n">specificity</span>
    
    <span class="n">positive_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> 
                            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">false_positives</span><span class="p">)))</span>
    
    <span class="n">negative_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> 
                            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">false_negatives</span><span class="p">)))</span>
    
    <span class="c1"># Create dictionary for results, and add results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">precision</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">recall</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;sensitivity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitivity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;specificity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">specificity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_predictive_value</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_predictive_value</span>
    
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-function-to-scale-data">
<h2>Define function to scale data<a class="headerlink" href="#define-function-to-scale-data" title="Permalink to this headline">¶</a></h2>
<p>In neural networks it is common to to scale input data 0-1 rather than use standardisation (subtracting mean and dividing by standard deviation) of each feature).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scale_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scale data 0-1 based on min and max in training set&quot;&quot;&quot;</span>
    
    <span class="c1"># Initialise a new scaling object for normalising input data</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

    <span class="c1"># Set up the scaler just on the training set</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Apply the scaler to the training and test sets</span>
    <span class="n">train_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">test_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_sc</span><span class="p">,</span> <span class="n">test_sc</span>
    
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-data">
<h2>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/processed_data.csv&#39;</span><span class="p">)</span>
<span class="c1"># Make all data &#39;float&#39; type</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># X = all &#39;data&#39; except the &#39;survived&#39; column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span> <span class="c1"># y = &#39;survived&#39; column from &#39;data&#39;</span>
<span class="c1"># Convert to NumPy as required for k-fold splits</span>
<span class="n">X_np</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_np</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="set-up-neural-net">
<h1>Set up neural net<a class="headerlink" href="#set-up-neural-net" title="Permalink to this headline">¶</a></h1>
<p>Here we use the <code class="docutils literal notranslate"><span class="pre">sequential</span></code> method to set up a PyTorch neural network. This simpler method assumes each layer occurs in sequence. Though simpler, it lacks some flexibility, and does not allow for easy debugging by setting a breakpoint in the middle of the training sequence.</p>
<p>We will put construction of the neural net into a separate function.</p>
<p>The neural net is a relatively simple network. The inputs are connected to two hidden layers (of 240 and 50 nodes) before being connected to two output nodes corresponding to each class (died and survived). It also contains some useful additions (batch normalisation and dropout) as described below.</p>
<p>The layers of the network are:</p>
<ol class="simple">
<li><p>An input layer (which does not need to be explicitly defined when using the <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> method)</p></li>
<li><p>A linear fully-connected (dense) layer.This is defined by the number of inputs (the number of input features) and the number of nodes/outputs. Each node will receive the values of all the inputs (which will either be the feature data for the input layer, or the outputs from the previous layer - so that if the previous layer had 10 nodes, then each node of the current layer would have 10 inputs, one from each node of the previous layer). It is a linear layer because the output of the node at this point is a linear function of the dot product of the weights and input values. We will expand out feature data set up to 240 outputs.</p></li>
<li><p>A batch normalisation layer. This is not usually used for small models, but can increase the speed of training and stability for larger models. It is added here as an example of how to include it (in large models all dense layers would be followed by a batch normalisation layer). Using batch normalisation usually allows for a higher learning rate. The layer definition includes the number of inputs to normalise.</p></li>
<li><p>A dropout layer. This layer randomly sets outputs from the preceding layer to zero during training (a different set of outputs is zeroed for each training iteration). This helps prevent over-fitting of the model to the training data. Typically between 0.1 and 0.3 outputs are set to zero (<code class="docutils literal notranslate"><span class="pre">p=0.1</span></code> means 10% of outputs are set to zero).</p></li>
<li><p>An activation layer. In this case ReLU (rectified linear unit). ReLU activation is most common for the inner layers of a neural network. Negative input values are set to zero. Positive input values are left unchanged.</p></li>
<li><p>A second linear fully connected layer which reduces the network down to 50 nodes. This is again followed by batch normalisation, dropout and ReLU activation layers.</p></li>
<li><p>A final fully connected linear layer of two nodes (more nodes could be used for more classes).</p></li>
<li><p>Apply sigmoid activation to convert each output node to range 0-1 output.</p></li>
</ol>
<p>The output of the net are two numbers (corresponding to scored for died/survived) between 0 and 1. These do not necessarily add up exactly to one. The one with the highest value is taken as the classification result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_net</span><span class="p">(</span><span class="n">number_features</span><span class="p">):</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">number_features</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">240</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mi">240</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>            
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
    
    <span class="k">return</span> <span class="n">net</span>
</pre></div>
</div>
</div>
</div>
<section id="run-the-model-with-k-fold-validation">
<h2>Run the model with k-fold validation<a class="headerlink" href="#run-the-model-with-k-fold-validation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up lists to hold results</span>
<span class="n">training_acc_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Set up splits</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Loop through the k-fold splits</span>
<span class="n">k_counter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">):</span>
    <span class="n">k_counter</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;K_fold </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k_counter</span><span class="p">),</span><span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    
    <span class="c1"># Get X and Y train/test</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_np</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X_np</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_np</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_np</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
    <span class="c1"># Scale X data</span>
    <span class="n">X_train_sc</span><span class="p">,</span> <span class="n">X_test_sc</span> <span class="o">=</span> <span class="n">scale_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Define network</span>
    <span class="n">number_features</span> <span class="o">=</span> <span class="n">X_train_sc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>        
    <span class="n">net</span> <span class="o">=</span> <span class="n">make_net</span><span class="p">(</span><span class="n">number_features</span><span class="p">)</span>
    
    <span class="c1">### Train model</span>
    <span class="c1"># Note: Lots of these parameters may be fine tuned</span>
    
    <span class="c1"># Set batch size (cases per batch - commonly 8-64)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="c1"># Epochs (number of times to pass over data)</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="c1"># Learning rate (how much each bacth updates the model)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.003</span>
    <span class="c1"># Calculate numebr of batches</span>
    <span class="n">batch_no</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_sc</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
    
    <span class="c1"># Set up optimizer for classification</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="c1"># Train model by passing through the data the required number of epochs</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_no</span><span class="p">):</span>
            
            <span class="c1"># Get X and y batch data</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">batch_size</span>
            <span class="n">x_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train_sc</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
            <span class="n">y_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
            
            <span class="c1"># These steps train the model: Forward + Backward + Optimize</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># reset optimizer</span>
            <span class="n">ypred_var</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_var</span><span class="p">)</span> <span class="c1"># predict y</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">ypred_var</span><span class="p">,</span> <span class="n">y_var</span><span class="p">)</span> <span class="c1"># Calculate loss</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Back propagate loss through network</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># Update network to reduce loss</span>
            
    <span class="c1">### Test model (print results for each k-fold iteration)</span>
    
    <span class="n">test_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_train_sc</span><span class="p">))</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_var</span><span class="p">)</span>
    <span class="n">values</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred_train</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">training_acc_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_train</span><span class="p">)</span>
 
    <span class="n">test_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_test_sc</span><span class="p">))</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_var</span><span class="p">)</span>
    <span class="n">values</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred_test</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">accuracy_test</span><span class="p">)</span>
    <span class="n">test_acc_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K_fold 1 0.770949720670391
K_fold 2 0.7921348314606742
K_fold 3 0.8258426966292135
K_fold 4 0.8202247191011236
K_fold 5 0.848314606741573
</pre></div>
</div>
</div>
</div>
</section>
<section id="show-training-and-test-results">
<h2>Show training and test results<a class="headerlink" href="#show-training-and-test-results" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show individual accuracies on training data</span>
<span class="n">training_acc_results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.8665730337078652,
 0.8639551192145862,
 0.8513323983169705,
 0.8555399719495091,
 0.8415147265077139]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show individual accuracies on test data</span>
<span class="n">test_acc_results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.770949720670391,
 0.7921348314606742,
 0.8258426966292135,
 0.8202247191011236,
 0.848314606741573]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get mean results</span>
<span class="n">mean_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_acc_results</span><span class="p">)</span>
<span class="n">mean_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_acc_results</span><span class="p">)</span>

<span class="c1"># Display each to three decimal places</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">{0:.3f}</span><span class="s1">, </span><span class="si">{1:.3}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_training</span><span class="p">,</span><span class="n">mean_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.856, 0.811
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-results-box-plot">
<h2>Plot results: Box Plot<a class="headerlink" href="#plot-results-box-plot" title="Permalink to this headline">¶</a></h2>
<p>Box plots show median (orange line), the second and third quartiles (the box), the range (excluding outliers), and any outliers as ‘whisker’ points. Outliers, by convention, are considered to be any points outside of the quartiles +/- 1.5 times the interquartile range. The limit for outliers may be changed using the optional <code class="docutils literal notranslate"><span class="pre">whis</span></code> argument in the boxplot.</p>
<p>Medians tend to be an easy reliable guide to the centre of a distribution (i.e. look at the medians to see whether a fit is improving or not, but also look at the box plot to see how much variability there is).</p>
<p>Test sets tend to be more variable in their accuracy measures. Can you think why?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up X data </span>
<span class="n">x_for_box</span> <span class="o">=</span> <span class="p">[</span><span class="n">training_acc_results</span><span class="p">,</span> <span class="n">test_acc_results</span><span class="p">]</span>

<span class="c1"># Set up X labels</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="s1">&#39;Test&#39;</span><span class="p">]</span> 

<span class="c1"># Set up figure</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Add subplot (can be used to define multiple plots in same figure)</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="c1"># Define Box Plot (`widths` is optional)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x_for_box</span><span class="p">,</span> 
            <span class="n">widths</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">whis</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Set X and Y labels</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>

<span class="c1"># Show plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/45_pytorch_simple_20_0.png" src="_images/45_pytorch_simple_20_0.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="25_tensorflow_bagging.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">TensorFlow Bagging</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="46_pytorch_class.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">PyTorch class-based neural net</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Michael Allen & Kerry Pearn<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>