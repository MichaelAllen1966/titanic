
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>A Random Forest model &#8212; Titanic Survival Machine Learning</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification" href="18_random_forest_roc.html" />
    <link rel="prev" title="Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)" href="16_imbalanced%20_data_smote.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Titanic Survival Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="front_page.html">
   Titanic Survival
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Setting up an environment file to run these notebooks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="setup.html">
   Setting up an environment
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Data preprocessing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_preprocessing.html">
   Kaggle Titanic survival - data preprocessing
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Basic methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="02_logistic_regression.html">
   Logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_k_fold.html">
   Measuring model accuracy with K-fold stratification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_regularisation.html">
   Avoiding over-fitting with regularisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_accuracy_standalone.html">
   Accuracy measurements in machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_accuracy_logistic_regression.html">
   Application of alternative accuracy measurements to a logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_learning_curve.html">
   Learning curves - how much data do we need?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_roc.html">
   Receiver Operator Characteristic (ROC) curve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="50_check_calibration.html">
   Checking model calibration
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Feature selection and expansion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09_feature_selection_1_univariate.html">
   Feature selection using univariate statistical selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_feature_selection_2_forward.html">
   Feature selection using forward selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_feature_selection_3_backward.html">
   Feature selection using backward elimination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feature_expansion.html">
   Feature expansion
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Working with imbalanced data sets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13_imbalanced%20_data_weighting.html">
   Dealing with imbalanced data by model weighting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_imbalanced%20_data_sampling.html">
   Dealing with imbalanced data by under or over sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_imbalanced%20_data_threshold.html">
   Dealing with imbalanced data by changing classification cut-off levels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_imbalanced%20_data_smote.html">
   Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Random forest model
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   A Random Forest model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_random_forest_roc.html">
   Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  TensorFlow neural nets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="19_tensorflow_1.html">
   TensorFlow neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_tensorflow_api.html">
   TensorFlow api-based neural net.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_tensorflow_roc.html">
   TensorFlow Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_tensorflow_deep_wide.html">
   TensorFlow ‘Wide and Deep’ neural nets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25_tensorflow_bagging.html">
   TensorFlow Bagging
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Model explainability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="26_logistic_regression_shap.html">
   Explaining model predictions with Shapley values
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/17_random_forest.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-modules">
   Load modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-data">
   Download data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-function-to-calculate-accuracy">
   Define function to calculate accuracy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-the-model-with-k-fold-validation">
   Run the model with k-fold validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#show-results-and-feature-importance">
   Show results and feature importance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#observations">
   Observations
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="a-random-forest-model">
<h1>A Random Forest model<a class="headerlink" href="#a-random-forest-model" title="Permalink to this headline">¶</a></h1>
<p>Our previous work has all been based on logistic regression, which is the most common ‘standard model’ against which all other models are compared.</p>
<p>In this notebook we swap out the logistic regression model for a Random Forest model. Random Forests are often chosen for classification based on structured data (i.e. when we have specific features of data, rather than unstructured data like a picture or a sound file).</p>
<p>Random Forests are based on constructing multiple decision trees, each of which sees only part of the data for each case, and only has limited ‘branches’. Random Forests tend to be less prone to over-fitting than decision trees. For more on the basis of Random Forests see:</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Random_forest">https://en.wikipedia.org/wiki/Random_forest</a></p>
<p>Note in this example how similar the code is to our previous logistic regression model. A couple of notable changes are:</p>
<ul class="simple">
<li><p>Data for Random Forest models do not need standardisation; we use the raw data.</p></li>
<li><p>Rather than having coefficients, we output model ‘importances’ which reflect how influential a feature is in deciding classification. This is accessed through examining <code class="docutils literal notranslate"><span class="pre">model.feature_importances_</span></code>.</p></li>
</ul>
<p>Here we will again use stratified K-fold validation to test the model performance. We will use default settings for the Random Forest model.</p>
<div class="section" id="load-modules">
<h2>Load modules<a class="headerlink" href="#load-modules" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-data">
<h2>Download data<a class="headerlink" href="#download-data" title="Permalink to this headline">¶</a></h2>
<p>Run the following code if data for Titanic survival has not been previously downloaded.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download_required</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">download_required</span><span class="p">:</span>
    
    <span class="c1"># Download processed data:</span>
    <span class="n">address</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/MichaelAllen1966/&#39;</span> <span class="o">+</span> \
                <span class="s1">&#39;1804_python_healthcare/master/titanic/data/processed_data.csv&#39;</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">address</span><span class="p">)</span>

    <span class="c1"># Create a data subfolder if one does not already exist</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">data_directory</span> <span class="o">=</span><span class="s1">&#39;./data/&#39;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">data_directory</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">data_directory</span><span class="p">)</span>

    <span class="c1"># Save data</span>
    <span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">data_directory</span> <span class="o">+</span> <span class="s1">&#39;processed_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="load-data">
<h2>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data &amp; drop passenger ID</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/processed_data.csv&#39;</span><span class="p">)</span>

<span class="c1"># Make all data &#39;float&#39; type</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Split data into two DataFrames</span>
<span class="n">X_df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_df</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>

<span class="c1"># Convert DataFrames to NumPy arrays</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_df</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y_df</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-function-to-calculate-accuracy">
<h2>Define function to calculate accuracy<a class="headerlink" href="#define-function-to-calculate-accuracy" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates a range of accuracy scores from observed and predicted classes.</span>
<span class="sd">    </span>
<span class="sd">    Takes two list or NumPy arrays (observed class values, and predicted class </span>
<span class="sd">    values), and returns a dictionary of results.</span>
<span class="sd">    </span>
<span class="sd">     1) observed positive rate: proportion of observed cases that are +ve</span>
<span class="sd">     2) Predicted positive rate: proportion of predicted cases that are +ve</span>
<span class="sd">     3) observed negative rate: proportion of observed cases that are -ve</span>
<span class="sd">     4) Predicted negative rate: proportion of predicted cases that are -ve  </span>
<span class="sd">     5) accuracy: proportion of predicted results that are correct    </span>
<span class="sd">     6) precision: proportion of predicted +ve that are correct</span>
<span class="sd">     7) recall: proportion of true +ve correctly identified</span>
<span class="sd">     8) f1: harmonic mean of precision and recall</span>
<span class="sd">     9) sensitivity: Same as recall</span>
<span class="sd">    10) specificity: Proportion of true -ve identified:        </span>
<span class="sd">    11) positive likelihood: increased probability of true +ve if test +ve</span>
<span class="sd">    12) negative likelihood: reduced probability of true +ve if test -ve</span>
<span class="sd">    13) false positive rate: proportion of false +ves in true -ve patients</span>
<span class="sd">    14) false negative rate: proportion of false -ves in true +ve patients</span>
<span class="sd">    15) true positive rate: Same as recall</span>
<span class="sd">    16) true negative rate</span>
<span class="sd">    17) positive predictive value: chance of true +ve if test +ve</span>
<span class="sd">    18) negative predictive value: chance of true -ve if test -ve</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Converts list to NumPy arrays</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    
    <span class="c1"># Calculate accuracy scores</span>
    <span class="n">observed_positives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">observed_negatives</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">predicted_positives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">predicted_negatives</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="n">true_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">false_positives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_positives</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="n">true_negatives</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">observed_negatives</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">observed</span><span class="p">)</span>
    
    <span class="n">precision</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span>
                 <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">false_positives</span><span class="p">)))</span>
        
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">recall</span>
    
    <span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">((</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">))</span>
    
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    
    <span class="n">positive_likelihood</span> <span class="o">=</span> <span class="n">sensitivity</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span><span class="p">)</span>
    
    <span class="n">negative_likelihood</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span><span class="p">)</span> <span class="o">/</span> <span class="n">specificity</span>
    
    <span class="n">false_positive_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">specificity</span>
    
    <span class="n">false_negative_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sensitivity</span>
    
    <span class="n">true_positive_rate</span> <span class="o">=</span> <span class="n">sensitivity</span>
    
    <span class="n">true_negative_rate</span> <span class="o">=</span> <span class="n">specificity</span>
    
    <span class="n">positive_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_positives</span><span class="p">)</span> <span class="o">/</span> 
                                 <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">))</span>
    
    <span class="n">negative_predictive_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> 
                                  <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">))</span>
    
    <span class="c1"># Create dictionary for results, and add results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">observed_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_positives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_negatives</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">precision</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">recall</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;sensitivity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sensitivity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;specificity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">specificity</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_likelihood&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_likelihood</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;false_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">false_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_positive_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;true_negative_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_negative_rate</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;positive_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_predictive_value</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;negative_predictive_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">negative_predictive_value</span>
    
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="run-the-model-with-k-fold-validation">
<h2>Run the model with k-fold validation<a class="headerlink" href="#run-the-model-with-k-fold-validation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up lists to hold results for each k-fold run</span>
<span class="n">replicate_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">replicate_precision</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">replicate_recall</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">replicate_f1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">replicate_predicted_positive_rate</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">replicate_observed_positive_rate</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Set up DataFrame for feature importances</span>
<span class="n">importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X_df</span><span class="p">))</span>

<span class="c1"># Convert DataFrames to NumPy arrays</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_df</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y_df</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Set up splits</span>
<span class="n">number_of_splits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">number_of_splits</span><span class="p">)</span>
<span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Loop through the k-fold splits</span>
<span class="n">k_fold_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    
    <span class="c1"># Get X and Y train/test</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
    <span class="c1"># Set up and fit model (n_jobs=-1 uses all cores on a computer)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Predict test set labels and get accuracy scores</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy_scores</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
    <span class="n">replicate_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">replicate_precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">])</span>
    <span class="n">replicate_recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">])</span>
    <span class="n">replicate_f1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">])</span>
    <span class="n">replicate_predicted_positive_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;predicted_positive_rate&#39;</span><span class="p">])</span>
    <span class="n">replicate_observed_positive_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">accuracy_scores</span><span class="p">[</span><span class="s1">&#39;observed_positive_rate&#39;</span><span class="p">])</span>
    
    <span class="c1"># Record feature importances</span>
    <span class="n">col_title</span> <span class="o">=</span> <span class="s1">&#39;split_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">k_fold_count</span><span class="p">)</span>
    <span class="n">importances</span><span class="p">[</span><span class="n">col_title</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span>
    <span class="n">k_fold_count</span> <span class="o">+=</span><span class="mi">1</span>
    
<span class="c1"># Transfer results to list and add to data frame</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">()</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_accuracy</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_precision</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_recall</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_f1</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;predicted positive rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_predicted_positive_rate</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;observed positive rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">replicate_observed_positive_rate</span><span class="p">)</span>

<span class="c1"># Get average of feature importances, and sort</span>
<span class="n">importance_mean</span> <span class="o">=</span> <span class="n">importances</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">importance_mean</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="show-results-and-feature-importance">
<h2>Show results and feature importance<a class="headerlink" href="#show-results-and-feature-importance" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy                   0.801423
precision                  0.747805
recall                     0.730924
f1                         0.736352
predicted positive rate    0.375943
observed positive rate     0.383833
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">importance_mean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>male                   0.232531
Fare                   0.218718
Age                    0.215120
Pclass                 0.058164
CabinNumber            0.056248
SibSp                  0.047701
Parch                  0.039698
CabinNumberImputed     0.018376
CabinLetterImputed     0.016551
AgeImputed             0.016459
CabinLetter_missing    0.016114
Embarked_S             0.015642
Embarked_C             0.013035
Embarked_Q             0.007959
CabinLetter_E          0.005723
CabinLetter_C          0.005667
CabinLetter_B          0.004911
CabinLetter_D          0.004296
CabinLetter_A          0.003754
CabinLetter_F          0.001752
CabinLetter_G          0.001063
CabinLetter_T          0.000219
EmbarkedImputed        0.000163
Embarked_missing       0.000136
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="observations">
<h2>Observations<a class="headerlink" href="#observations" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Without any optimisation we observe accuracy similar to, or a little higher than, logistic regression.</p></li>
<li><p>Unlike logistic regression we see a good balance between precision and recall, rather than a bias towards the majority class.</p></li>
<li><p>Performance of the model may be tested and optimised as we previously did for logistic regression (e.g. construct ROC curves, perform feature selection, consider over-sampling or under-sampling as required, examine learning curves).</p></li>
</ul>
<p>For further notes on the sklearn Random Forest model (and which parameters may be fine-tuned, e.g. with random search or grid search as we did with the logistic regression model) please see the help pages for the Random Forest model, or refer to:</p>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="16_imbalanced%20_data_smote.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="18_random_forest_roc.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Michael Allen & Kerry Pearn<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>