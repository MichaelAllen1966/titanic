
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Logistic regression model &#8212; Titanic Survival Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Measuring model accuracy with K-fold stratification" href="03_k_fold.html" />
    <link rel="prev" title="Kaggle Titanic survival - data preprocessing" href="01_preprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Titanic Survival Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="front_page.html">
                    Titanic Survival
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Setting up an environment file to run these notebooks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="setup.html">
   Setting up an environment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data preprocessing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_preprocessing.html">
   Kaggle Titanic survival - data preprocessing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic methods
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_k_fold.html">
   Measuring model accuracy with K-fold stratification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_regularisation.html">
   Avoiding over-fitting with regularisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_accuracy_standalone.html">
   Accuracy measurements in machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_accuracy_logistic_regression.html">
   Application of alternative accuracy measurements to a logistic regression model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_learning_curve.html">
   Learning curves - how much data do we need?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_roc.html">
   Receiver Operator Characteristic (ROC) curve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="50_check_calibration.html">
   Checking model calibration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="53_bagging.html">
   Measuring uncertainty in probability predictions using bagging
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimising machine learning models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="40_optuna.html">
   Optimising machine learning models with Optuna
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Feature selection and expansion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09_feature_selection_1_univariate.html">
   Feature selection using univariate statistical selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_feature_selection_2_forward.html">
   Feature selection using forward selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_feature_selection_3_backward.html">
   Feature selection using backward elimination
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feature_expansion.html">
   Feature expansion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Working with imbalanced data sets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13_imbalanced%20_data_weighting.html">
   Dealing with imbalanced data by model weighting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_imbalanced%20_data_sampling.html">
   Dealing with imbalanced data by under or over sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15_imbalanced%20_data_threshold.html">
   Dealing with imbalanced data by changing classification cut-off levels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_imbalanced%20_data_smote.html">
   Dealing with imbalanced data by enhancing the minority class with synthetic data (SMOTE: Synthetic Minority Over-sampling Technique)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="51_sampling_and_calibration.html">
   The effect of over-sampling and under-sampling on model calibration
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Random forest and XGBoost models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17_random_forest.html">
   A Random Forest model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18_random_forest_roc.html">
   Random Forest Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="32_xgboost.html">
   XGBoost as a replacement for Random Forest
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TensorFlow neural nets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="19_tensorflow_1.html">
   TensorFlow neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_tensorflow_api.html">
   TensorFlow api-based neural net.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21_tensorflow_roc.html">
   TensorFlow Receiver Operator Characteristic (ROC) curve and balancing of model classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22_tensorflow_deep_wide.html">
   TensorFlow ‘Wide and Deep’ neural nets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25_tensorflow_bagging.html">
   TensorFlow Bagging
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pytorch neural nets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="45_pytorch_simple.html">
   PyTorch simple sequential neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="46_pytorch_class.html">
   PyTorch class-based neural net
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="47_pytorch_gpu.html">
   PyTorch class-based neural net using GPU if avaliable
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model explainability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="26_logistic_regression_shap.html">
   Explaining model predictions with Shapley values - Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="27_random_forest_shap.html">
   Explaining model predictions with Shapley values - Random Forest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="28_neural_net_shap.html">
   Explaining model predictions with Shapley values - Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="90_shap_interactions_on_titanic.html">
   Examining interactions between features with SHAP interactions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="30_synthetic_data%20_SMOTE.html">
   Creating synthetic Titanic passenger data with SMOTE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="52_pytorch_softmax_sigmoid.html">
   A comparison of calibration of neural networks using a single sigmoid output or dual SoftMax or Sigmoid outputs
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/02_logistic_regression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-modules">
   Load modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examine-loaded-data">
   Examine loaded data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#looking-at-a-summary-of-passengers-who-survived-or-did-not-survive">
   Looking at a summary of passengers who survived or did not survive
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#divide-into-x-features-and-y-labels">
   Divide into X (features) and y (labels)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#divide-into-training-and-tets-sets">
   Divide into training and tets sets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardise-data">
   Standardise data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-logistic-regression-model">
   Fit logistic regression model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predict-values">
   Predict values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculate-accuracy">
   Calculate accuracy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examining-the-model-coefficients-weights">
   Examining the model coefficients (weights)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#show-predicted-probabilities">
   Show predicted probabilities
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Logistic regression model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-modules">
   Load modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examine-loaded-data">
   Examine loaded data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#looking-at-a-summary-of-passengers-who-survived-or-did-not-survive">
   Looking at a summary of passengers who survived or did not survive
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#divide-into-x-features-and-y-labels">
   Divide into X (features) and y (labels)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#divide-into-training-and-tets-sets">
   Divide into training and tets sets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardise-data">
   Standardise data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-logistic-regression-model">
   Fit logistic regression model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predict-values">
   Predict values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculate-accuracy">
   Calculate accuracy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examining-the-model-coefficients-weights">
   Examining the model coefficients (weights)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#show-predicted-probabilities">
   Show predicted probabilities
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="logistic-regression-model">
<h1>Logistic regression model<a class="headerlink" href="#logistic-regression-model" title="Permalink to this headline">#</a></h1>
<p>The data includes:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>survival</p></td>
<td><p>Survival (0 = No, 1 = Yes)</p></td>
</tr>
<tr class="row-odd"><td><p>pclass</p></td>
<td><p>Ticket class</p></td>
</tr>
<tr class="row-even"><td><p>sex</p></td>
<td><p>Sex</p></td>
</tr>
<tr class="row-odd"><td><p>Age</p></td>
<td><p>Age in years</p></td>
</tr>
<tr class="row-even"><td><p>sibsp</p></td>
<td><p># of siblings / spouses aboard the Titanic</p></td>
</tr>
<tr class="row-odd"><td><p>parch</p></td>
<td><p># of parents / children aboard the Titanic</p></td>
</tr>
<tr class="row-even"><td><p>ticket</p></td>
<td><p>Ticket number</p></td>
</tr>
<tr class="row-odd"><td><p>fare</p></td>
<td><p>Passenger fare</p></td>
</tr>
<tr class="row-even"><td><p>cabin</p></td>
<td><p>Cabin number</p></td>
</tr>
<tr class="row-odd"><td><p>embarked</p></td>
<td><p>Port of Embarkation(C=Cherbourg, Q=Queenstown, S=Southampton)</p></td>
</tr>
</tbody>
</table>
<section id="logistic-regression">
<h2>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h2>
<p>In this example we will use logistic regression (see <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a>).</p>
<p>For an introductory video on logistic regression see: <a class="reference external" href="https://www.youtube.com/watch?v=yIYKR4sgzI8">https://www.youtube.com/watch?v=yIYKR4sgzI8</a></p>
<p>Logistic regression takes a range of features (which we will normalise/standardise to put on the same scale) and returns a probability that a certain classification (survival in this case) is true.</p>
<p>We will go through the following steps:</p>
<ul class="simple">
<li><p>Download and save pre-processed data</p></li>
<li><p>Split data into features (X) and label (y)</p></li>
<li><p>Split data into training and test sets (we will test on data that has not been used to fit the model)</p></li>
<li><p>Standardise data</p></li>
<li><p>Fit a logistic regression model (from sklearn)</p></li>
<li><p>Predict survival of the test set, and assess accuracy</p></li>
<li><p>Review model coefficients (weights) to see importance of features</p></li>
<li><p>Show probability of survival for passengers</p></li>
</ul>
</section>
<section id="load-modules">
<h2>Load modules<a class="headerlink" href="#load-modules" title="Permalink to this headline">#</a></h2>
<p>A standard Anaconda install of Python (<a class="reference external" href="https://www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a>) contains all the necessary modules.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># Import machine learning methods</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-data">
<h2>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">#</a></h2>
<p>The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).
If data has already been downloaded that cell may be skipped.</p>
<p>Code that was used to pre-process the data ready for machine learning may be found at:
<a class="reference external" href="https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb">https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download_required</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">download_required</span><span class="p">:</span>
    
    <span class="c1"># Download processed data:</span>
    <span class="n">address</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/MichaelAllen1966/&#39;</span> <span class="o">+</span> \
                <span class="s1">&#39;1804_python_healthcare/master/titanic/data/processed_data.csv&#39;</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">address</span><span class="p">)</span>

    <span class="c1"># Create a data subfolder if one does not already exist</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">data_directory</span> <span class="o">=</span><span class="s1">&#39;./data/&#39;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">data_directory</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">data_directory</span><span class="p">)</span>

    <span class="c1"># Save data</span>
    <span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">data_directory</span> <span class="o">+</span> <span class="s1">&#39;processed_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/processed_data.csv&#39;</span><span class="p">)</span>
<span class="c1"># Make all data &#39;float&#39; type</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="examine-loaded-data">
<h2>Examine loaded data<a class="headerlink" href="#examine-loaded-data" title="Permalink to this headline">#</a></h2>
<p>The data is in the form of a Pandas DataFrame, so we have column headers providing information of what is contained in each column.</p>
<p>We will use the DataFrame <code class="docutils literal notranslate"><span class="pre">.head()</span></code> method to show the first few rows of the imported DataFrame. By default this shows the first 5 rows. Here we will look at the first 10.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>AgeImputed</th>
      <th>EmbarkedImputed</th>
      <th>CabinLetterImputed</th>
      <th>...</th>
      <th>Embarked_missing</th>
      <th>CabinLetter_A</th>
      <th>CabinLetter_B</th>
      <th>CabinLetter_C</th>
      <th>CabinLetter_D</th>
      <th>CabinLetter_E</th>
      <th>CabinLetter_F</th>
      <th>CabinLetter_G</th>
      <th>CabinLetter_T</th>
      <th>CabinLetter_missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>22.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>7.2500</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>38.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>71.2833</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>26.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.9250</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>35.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>53.1000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>35.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.0500</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.4583</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>54.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>51.8625</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>21.0750</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>27.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>11.1333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>14.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>30.0708</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 26 columns</p>
</div></div></div>
</div>
<p>We can also show a summary of the data with the <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>AgeImputed</th>
      <th>EmbarkedImputed</th>
      <th>CabinLetterImputed</th>
      <th>...</th>
      <th>Embarked_missing</th>
      <th>CabinLetter_A</th>
      <th>CabinLetter_B</th>
      <th>CabinLetter_C</th>
      <th>CabinLetter_D</th>
      <th>CabinLetter_E</th>
      <th>CabinLetter_F</th>
      <th>CabinLetter_G</th>
      <th>CabinLetter_T</th>
      <th>CabinLetter_missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>...</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.361582</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
      <td>0.198653</td>
      <td>0.002245</td>
      <td>0.771044</td>
      <td>...</td>
      <td>0.002245</td>
      <td>0.016835</td>
      <td>0.052750</td>
      <td>0.066218</td>
      <td>0.037037</td>
      <td>0.035915</td>
      <td>0.014590</td>
      <td>0.004489</td>
      <td>0.001122</td>
      <td>0.771044</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>13.019697</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
      <td>0.399210</td>
      <td>0.047351</td>
      <td>0.420397</td>
      <td>...</td>
      <td>0.047351</td>
      <td>0.128725</td>
      <td>0.223659</td>
      <td>0.248802</td>
      <td>0.188959</td>
      <td>0.186182</td>
      <td>0.119973</td>
      <td>0.066890</td>
      <td>0.033501</td>
      <td>0.420397</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>22.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>35.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 26 columns</p>
</div></div></div>
</div>
<p>The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop Passengerid (axis=1 indicates we are removing a column rather than a row)</span>
<span class="c1"># We drop passenger ID as it is not original data</span>

<span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="looking-at-a-summary-of-passengers-who-survived-or-did-not-survive">
<h2>Looking at a summary of passengers who survived or did not survive<a class="headerlink" href="#looking-at-a-summary-of-passengers-who-survived-or-did-not-survive" title="Permalink to this headline">#</a></h2>
<p>Before running machine learning models, it is always good to have a look at your data. Here we will separate passengers who survived from those who died, and we will have a look at differences in features.</p>
<p>We will use a <em>mask</em> to select and filter passengers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="c1"># Mask for passengers who survive</span>
<span class="n">survived</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="c1"># filter using mask</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="c1"># Mask for passengers who died</span>
<span class="n">died</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="c1"># filter using mask</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s look at average (mean) values for <code class="docutils literal notranslate"><span class="pre">survived</span></code> and <code class="docutils literal notranslate"><span class="pre">died</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">survived</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Survived                1.000000
Pclass                  1.950292
Age                    28.291433
SibSp                   0.473684
Parch                   0.464912
Fare                   48.395408
AgeImputed              0.152047
EmbarkedImputed         0.005848
CabinLetterImputed      0.602339
CabinNumber            18.961988
CabinNumberImputed      0.611111
male                    0.318713
Embarked_C              0.271930
Embarked_Q              0.087719
Embarked_S              0.634503
Embarked_missing        0.005848
CabinLetter_A           0.020468
CabinLetter_B           0.102339
CabinLetter_C           0.102339
CabinLetter_D           0.073099
CabinLetter_E           0.070175
CabinLetter_F           0.023392
CabinLetter_G           0.005848
CabinLetter_T           0.000000
CabinLetter_missing     0.602339
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">died</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Survived                0.000000
Pclass                  2.531876
Age                    30.028233
SibSp                   0.553734
Parch                   0.329690
Fare                   22.117887
AgeImputed              0.227687
EmbarkedImputed         0.000000
CabinLetterImputed      0.876138
CabinNumber             6.074681
CabinNumberImputed      0.885246
male                    0.852459
Embarked_C              0.136612
Embarked_Q              0.085610
Embarked_S              0.777778
Embarked_missing        0.000000
CabinLetter_A           0.014572
CabinLetter_B           0.021858
CabinLetter_C           0.043716
CabinLetter_D           0.014572
CabinLetter_E           0.014572
CabinLetter_F           0.009107
CabinLetter_G           0.003643
CabinLetter_T           0.001821
CabinLetter_missing     0.876138
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can make looking at them side by side more easy by putting these values in a new DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span> <span class="c1"># New empty DataFrame</span>
<span class="n">summary</span><span class="p">[</span><span class="s1">&#39;survived&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">survived</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">summary</span><span class="p">[</span><span class="s1">&#39;died&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">died</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s look at them side by side. See if you can spot what features you think might have influenced survival.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>died</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Survived</th>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>Pclass</th>
      <td>1.950292</td>
      <td>2.531876</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>28.291433</td>
      <td>30.028233</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>0.473684</td>
      <td>0.553734</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.464912</td>
      <td>0.329690</td>
    </tr>
    <tr>
      <th>Fare</th>
      <td>48.395408</td>
      <td>22.117887</td>
    </tr>
    <tr>
      <th>AgeImputed</th>
      <td>0.152047</td>
      <td>0.227687</td>
    </tr>
    <tr>
      <th>EmbarkedImputed</th>
      <td>0.005848</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>CabinLetterImputed</th>
      <td>0.602339</td>
      <td>0.876138</td>
    </tr>
    <tr>
      <th>CabinNumber</th>
      <td>18.961988</td>
      <td>6.074681</td>
    </tr>
    <tr>
      <th>CabinNumberImputed</th>
      <td>0.611111</td>
      <td>0.885246</td>
    </tr>
    <tr>
      <th>male</th>
      <td>0.318713</td>
      <td>0.852459</td>
    </tr>
    <tr>
      <th>Embarked_C</th>
      <td>0.271930</td>
      <td>0.136612</td>
    </tr>
    <tr>
      <th>Embarked_Q</th>
      <td>0.087719</td>
      <td>0.085610</td>
    </tr>
    <tr>
      <th>Embarked_S</th>
      <td>0.634503</td>
      <td>0.777778</td>
    </tr>
    <tr>
      <th>Embarked_missing</th>
      <td>0.005848</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>CabinLetter_A</th>
      <td>0.020468</td>
      <td>0.014572</td>
    </tr>
    <tr>
      <th>CabinLetter_B</th>
      <td>0.102339</td>
      <td>0.021858</td>
    </tr>
    <tr>
      <th>CabinLetter_C</th>
      <td>0.102339</td>
      <td>0.043716</td>
    </tr>
    <tr>
      <th>CabinLetter_D</th>
      <td>0.073099</td>
      <td>0.014572</td>
    </tr>
    <tr>
      <th>CabinLetter_E</th>
      <td>0.070175</td>
      <td>0.014572</td>
    </tr>
    <tr>
      <th>CabinLetter_F</th>
      <td>0.023392</td>
      <td>0.009107</td>
    </tr>
    <tr>
      <th>CabinLetter_G</th>
      <td>0.005848</td>
      <td>0.003643</td>
    </tr>
    <tr>
      <th>CabinLetter_T</th>
      <td>0.000000</td>
      <td>0.001821</td>
    </tr>
    <tr>
      <th>CabinLetter_missing</th>
      <td>0.602339</td>
      <td>0.876138</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="divide-into-x-features-and-y-labels">
<h2>Divide into X (features) and y (labels)<a class="headerlink" href="#divide-into-x-features-and-y-labels" title="Permalink to this headline">#</a></h2>
<p>We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).
By convention our features are called <code class="docutils literal notranslate"><span class="pre">X</span></code> (usually upper case to denote multiple features), and the label (survived or not) <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># X = all &#39;data&#39; except the &#39;survived&#39; column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span> <span class="c1"># y = &#39;survived&#39; column from &#39;data&#39;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="divide-into-training-and-tets-sets">
<h2>Divide into training and tets sets<a class="headerlink" href="#divide-into-training-and-tets-sets" title="Permalink to this headline">#</a></h2>
<p>When we test a machine learning model we should always test it on data that has not been used to train the model.
We will use sklearn’s <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> method to randomly split the data: 75% for training, and 25% for testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Pclass                  0.840603
 Age                    12.965456
 SibSp                   1.045440
 Parch                   0.829373
 Fare                   53.168865
 AgeImputed              0.390305
 EmbarkedImputed         0.054677
 CabinLetterImputed      0.424335
 CabinNumber            28.664011
 CabinNumberImputed      0.419561
 male                    0.481018
 Embarked_C              0.395037
 Embarked_Q              0.279581
 Embarked_S              0.450037
 Embarked_missing        0.054677
 CabinLetter_A           0.115375
 CabinLetter_B           0.228910
 CabinLetter_C           0.265752
 CabinLetter_D           0.174627
 CabinLetter_E           0.197088
 CabinLetter_F           0.121524
 CabinLetter_G           0.038691
 CabinLetter_T           0.038691
 CabinLetter_missing     0.424335
 dtype: float64, Pclass                  2.296407
 Age                    29.466826
 SibSp                   0.497006
 Parch                   0.389222
 Fare                   33.320958
 AgeImputed              0.187126
 EmbarkedImputed         0.002994
 CabinLetterImputed      0.764970
 CabinNumber            12.332335
 CabinNumberImputed      0.772455
 male                    0.637725
 Embarked_C              0.193114
 Embarked_Q              0.085329
 Embarked_S              0.718563
 Embarked_missing        0.002994
 CabinLetter_A           0.013473
 CabinLetter_B           0.055389
 CabinLetter_C           0.076347
 CabinLetter_D           0.031437
 CabinLetter_E           0.040419
 CabinLetter_F           0.014970
 CabinLetter_G           0.001497
 CabinLetter_T           0.001497
 CabinLetter_missing     0.764970
 dtype: float64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="standardise-data">
<h2>Standardise data<a class="headerlink" href="#standardise-data" title="Permalink to this headline">#</a></h2>
<p>We want all of out features to be on roughly the same scale. This generally leads to a better model, and also allows us to more easily compare the importance of different features.</p>
<p>One simple method is to scale all features 0-1 (by subtracting the minimum value for each value, and dividing by the new remaining maximum value).</p>
<p>But a more common method used in many machine learning methods is standardisation, where we use the mean and standard deviation of the training set of data to normalise the data. We subtract the mean of the training set values, and divide by the standard deviation of the training data. Note that the mean and standard deviation of the training data are used to standardise the test set data as well.</p>
<p>Here we will use sklearn’s <code class="docutils literal notranslate"><span class="pre">StandardScaler</span> <span class="pre">method</span></code>. This method also copes with problems we might otherwise have (such as if one feature has zero standard deviation in the training set).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>AgeImputed</th>
      <th>EmbarkedImputed</th>
      <th>CabinLetterImputed</th>
      <th>CabinNumber</th>
      <th>CabinNumberImputed</th>
      <th>...</th>
      <th>Embarked_missing</th>
      <th>CabinLetter_A</th>
      <th>CabinLetter_B</th>
      <th>CabinLetter_C</th>
      <th>CabinLetter_D</th>
      <th>CabinLetter_E</th>
      <th>CabinLetter_F</th>
      <th>CabinLetter_G</th>
      <th>CabinLetter_T</th>
      <th>CabinLetter_missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>335</th>
      <td>3.0</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7.8958</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>827</th>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>37.0042</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>270</th>
      <td>1.0</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>31.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>826</th>
      <td>3.0</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>56.4958</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>544</th>
      <td>1.0</td>
      <td>50.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>106.4250</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>86.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>166</th>
      <td>1.0</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>55.0000</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>33.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>813</th>
      <td>3.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>31.2750</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>679</th>
      <td>1.0</td>
      <td>36.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>512.3292</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>51.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>687</th>
      <td>3.0</td>
      <td>19.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.1708</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>558</th>
      <td>1.0</td>
      <td>39.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>79.6500</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>67.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>668 rows × 24 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">standardise_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    
    <span class="c1"># Initialise a new scaling object for normalising input data</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span> 

    <span class="c1"># Set up the scaler just on the training set</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

    <span class="c1"># Apply the scaler to the training and test sets</span>
    <span class="n">train_std</span><span class="o">=</span><span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">test_std</span><span class="o">=</span><span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_std</span><span class="p">,</span> <span class="n">test_std</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_std</span><span class="p">,</span> <span class="n">X_test_std</span> <span class="o">=</span> <span class="n">standardise_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fit-logistic-regression-model">
<h2>Fit logistic regression model<a class="headerlink" href="#fit-logistic-regression-model" title="Permalink to this headline">#</a></h2>
<p>Now we will fir a logistic regression model, using sklearn’s <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> method. Our machine learning model fitting is only two lines of code!
By using the name <code class="docutils literal notranslate"><span class="pre">model</span></code> for our logistic regression model we will make our model more interchangeable later on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;,
                   random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0,
                   warm_start=False)
</pre></div>
</div>
</div>
</div>
</section>
<section id="predict-values">
<h2>Predict values<a class="headerlink" href="#predict-values" title="Permalink to this headline">#</a></h2>
<p>Now we can use the trained model to predict survival. We will test the accuracy of both the training and test data sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict training and test set labels</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">)</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="calculate-accuracy">
<h2>Calculate accuracy<a class="headerlink" href="#calculate-accuracy" title="Permalink to this headline">#</a></h2>
<p>In this example we will measure accuracy simply as the proportion of passengers where we make the correct prediction. In a later notebook we will look at other measures of accuracy which explore false positives and false negatives in more detail.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred_train</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred_test</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Accuracy of predicting training data =&#39;</span><span class="p">,</span> <span class="n">accuracy_train</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Accuracy of predicting test data =&#39;</span><span class="p">,</span> <span class="n">accuracy_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy of predicting training data = 0.8278443113772455
Accuracy of predicting test data = 0.7623318385650224
</pre></div>
</div>
</div>
</div>
<p>Not bad - about 80% accuracy. You will probably see that accuracy of predicting the training set is usually higher than the test set. Because we are only testing one random sample, you may occasionally see otherwise. In later note books we will look at the best way to repeat multiple tests, and look at what to do if the accuracy of the training set is significantly higher than the test set (a problem called ‘over-fitting’).</p>
</section>
<section id="examining-the-model-coefficients-weights">
<h2>Examining the model coefficients (weights)<a class="headerlink" href="#examining-the-model-coefficients-weights" title="Permalink to this headline">#</a></h2>
<p>Not all features are equally important. And some may be of little or no use at all, unnecessarily increasing the complexity of the model. In a later notebook we will look at selecting features which add value to the model (or removing features that don’t).</p>
<p>Here we will look at the importance of features – how they affect our estimation of survival. These are known as the model <em>coefficients</em> (if you come from a traditional statistics background), or model <em>weights</em> (if you come from a machine learning background).</p>
<p>Because we have standardised our input data the magnitude of the weights may be compared as an indicator of their influence in the model. Weights with higher negative numbers mean that that feature correlates with reduced chance of survival. Weights with higher positive numbers mean that that feature correlates with increased chance of survival. Those weights with values closer to zero (either positive or negative) have less influence in the model.</p>
<p>We access the model weights my examining the model <code class="docutils literal notranslate"><span class="pre">coef_</span></code> attribute. The model may predict more than one outcome label, in which case we have weights for each label. Because we are predicting a signle label (survive or not), the weights are found in the first element (<code class="docutils literal notranslate"><span class="pre">[0]</span></code>) of the <code class="docutils literal notranslate"><span class="pre">coef_</span></code> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">co_eff</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">co_eff</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.73418553, -0.40986181, -0.35544658, -0.19006937,  0.14628888,
       -0.11822452,  0.09578928,  0.09296143,  0.06552385, -0.55844984,
       -1.40560834,  0.11123844,  0.03435464, -0.13062397,  0.09578928,
       -0.05538374, -0.11890361, -0.23386705,  0.09861583,  0.13506331,
        0.09892766,  0.15361326, -0.14199379,  0.09296143])
</pre></div>
</div>
</div>
</div>
<p>So we have an array of model weights.</p>
<p>Not very readable for us mere humans is it?!</p>
<p>We will transfer the weights array to a Pandas DataFrame. The array order is in the same order of the list of features of X, so we will put that those into the DataFrame as well. And we will sort by influence in the model. Because both large negative and positive values are more influential in the model we will take the <em>absolute</em> value of the weight (that is remove any negative sign), and then sort by that absolute value. That will give us a more readable table of most influential features in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">co_eff_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span> <span class="c1"># create empty DataFrame</span>
<span class="n">co_eff_df</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># Get feature names from X</span>
<span class="n">co_eff_df</span><span class="p">[</span><span class="s1">&#39;co_eff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">co_eff</span>
<span class="n">co_eff_df</span><span class="p">[</span><span class="s1">&#39;abs_co_eff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">co_eff</span><span class="p">)</span>
<span class="n">co_eff_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;abs_co_eff&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">co_eff_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>co_eff</th>
      <th>abs_co_eff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>male</td>
      <td>-1.405608</td>
      <td>1.405608</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Pclass</td>
      <td>-0.734186</td>
      <td>0.734186</td>
    </tr>
    <tr>
      <th>9</th>
      <td>CabinNumberImputed</td>
      <td>-0.558450</td>
      <td>0.558450</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Age</td>
      <td>-0.409862</td>
      <td>0.409862</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SibSp</td>
      <td>-0.355447</td>
      <td>0.355447</td>
    </tr>
    <tr>
      <th>17</th>
      <td>CabinLetter_C</td>
      <td>-0.233867</td>
      <td>0.233867</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Parch</td>
      <td>-0.190069</td>
      <td>0.190069</td>
    </tr>
    <tr>
      <th>21</th>
      <td>CabinLetter_G</td>
      <td>0.153613</td>
      <td>0.153613</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Fare</td>
      <td>0.146289</td>
      <td>0.146289</td>
    </tr>
    <tr>
      <th>22</th>
      <td>CabinLetter_T</td>
      <td>-0.141994</td>
      <td>0.141994</td>
    </tr>
    <tr>
      <th>19</th>
      <td>CabinLetter_E</td>
      <td>0.135063</td>
      <td>0.135063</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Embarked_S</td>
      <td>-0.130624</td>
      <td>0.130624</td>
    </tr>
    <tr>
      <th>16</th>
      <td>CabinLetter_B</td>
      <td>-0.118904</td>
      <td>0.118904</td>
    </tr>
    <tr>
      <th>5</th>
      <td>AgeImputed</td>
      <td>-0.118225</td>
      <td>0.118225</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Embarked_C</td>
      <td>0.111238</td>
      <td>0.111238</td>
    </tr>
    <tr>
      <th>20</th>
      <td>CabinLetter_F</td>
      <td>0.098928</td>
      <td>0.098928</td>
    </tr>
    <tr>
      <th>18</th>
      <td>CabinLetter_D</td>
      <td>0.098616</td>
      <td>0.098616</td>
    </tr>
    <tr>
      <th>6</th>
      <td>EmbarkedImputed</td>
      <td>0.095789</td>
      <td>0.095789</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Embarked_missing</td>
      <td>0.095789</td>
      <td>0.095789</td>
    </tr>
    <tr>
      <th>23</th>
      <td>CabinLetter_missing</td>
      <td>0.092961</td>
      <td>0.092961</td>
    </tr>
    <tr>
      <th>7</th>
      <td>CabinLetterImputed</td>
      <td>0.092961</td>
      <td>0.092961</td>
    </tr>
    <tr>
      <th>8</th>
      <td>CabinNumber</td>
      <td>0.065524</td>
      <td>0.065524</td>
    </tr>
    <tr>
      <th>15</th>
      <td>CabinLetter_A</td>
      <td>-0.055384</td>
      <td>0.055384</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Embarked_Q</td>
      <td>0.034355</td>
      <td>0.034355</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>So are three most influential features are:</p>
<ul class="simple">
<li><p>male (being male reduces probability of survival)</p></li>
<li><p>Pclass (lower class passengers, who have a higher class number, reduces probability of survival)</p></li>
<li><p>age (being older reduces probability of survival)</p></li>
</ul>
</section>
<section id="show-predicted-probabilities">
<h2>Show predicted probabilities<a class="headerlink" href="#show-predicted-probabilities" title="Permalink to this headline">#</a></h2>
<p>The predicted probabilities are for the two alternative classes 0 (does not survive) or 1 (survive).</p>
<p>Ordinarily we do not see these probabilities - the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method used above applies a cut-off of 0.5 to classify passengers into survived or not, but we can see the individual probabilities for each passenger.</p>
<p>Later we will use these to adjust sensitivity of our model to detecting survivors or non-survivors.</p>
<p>Each passenger has two values. These are the probability of not surviving (first value) or surviving (second value). Because we only have two possible classes we only need to look at one. Multiple values are important when there are more than one class being predicted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show first ten predicted classes</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">)</span>
<span class="n">classes</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show first ten predicted probabilities </span>
<span class="c1"># (note how the values relate to the classes predicted above)</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">)</span>
<span class="n">probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.34607729, 0.65392271],
       [0.93813559, 0.06186441],
       [0.46852979, 0.53147021],
       [0.84549935, 0.15450065],
       [0.95341715, 0.04658285],
       [0.88266921, 0.11733079],
       [0.86399098, 0.13600902],
       [0.90629119, 0.09370881],
       [0.99670517, 0.00329483],
       [0.81884463, 0.18115537]])
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="01_preprocessing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Kaggle Titanic survival - data preprocessing</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="03_k_fold.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Measuring model accuracy with K-fold stratification</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Michael Allen & Kerry Pearn<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>