{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch class-based neural net using GPU if avaliable\n",
    "\n",
    "This notebook is a repeat of the class-based method for PyTorch, but checks whether a GPU is available. GPUs signfocantly speed up neural network training when there are many features present, batch sizes are large, or the network is large.\n",
    "\n",
    "For smaller numbers of features, and for small networks, running on CPU may be faster (especially with modern multi-core CPUs).\n",
    "\n",
    "As opposed to TensorFlow, we must modify the code a little to use the GPU if it is available. We need to pass both the model and the data to the GPU as part of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn for pre-processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not previously downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "    # Make all data 'float' type\n",
    "    data = data.astype(float)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to scale data\n",
    "\n",
    "In neural networks it is common to to scale input data 0-1 rather than use standardisation (subtracting mean and dividing by standard deviation) of each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"Scale data 0-1 based on min and max in training set\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = MinMaxScaler()\n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_sc = sc.transform(X_train)\n",
    "    test_sc = sc.transform(X_test)\n",
    "    \n",
    "    return train_sc, test_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'\n",
    "# Convert to NumPy as required for k-fold splits\n",
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether a GPU is available \n",
    "\n",
    "The GPU must be of the 'CUDA' type (usually a NVIDIA GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up neural net\n",
    "\n",
    "Here we use the class-based method to set up a PyTorch neural network. The network is the same as the sequential network we previously used, but is built using \n",
    "\n",
    "We will put construction of the neural net into a separate function.\n",
    "\n",
    "The neural net is a relatively simple network. The inputs are connected to two hidden layers (of 240 and 50 nodes) before being connected to two output nodes corresponding to each class (died and survived). It also contains some useful additions (batch normalisation and dropout) as described below.\n",
    "\n",
    "The layers of the network are:\n",
    "\n",
    "1) An input layer (which does not need to be explicitly defined when using the `Sequential` method) \n",
    "\n",
    "2) A linear fully-connected (dense) layer.This is defined by the number of inputs (the number of input features) and the number of nodes/outputs. Each node will receive the values of all the inputs (which will either be the feature data for the input layer, or the outputs from the previous layer - so that if the previous layer had 10 nodes, then each node of the current layer would have 10 inputs, one from each node of the previous layer). It is a linear layer because the output of the node at this point is a linear function of the dot product of the weights and input values. We will expand out feature data set up to twice the number of input features. \n",
    "\n",
    "3) A batch normalisation layer. This is not usually used for small models, but can increase the speed of training and stability for larger models. It is added here as an example of how to include it (in large models all dense layers would be followed by a batch normalisation layer). Using batch normalisation usually allows for a higher learning rate. The layer definition includes the number of inputs to normalise.\n",
    "\n",
    "4) A dropout layer. This layer randomly sets outputs from the preceding layer to zero during training (a different set of outputs is zeroed for each training iteration). This helps prevent over-fitting of the model to the training data. Typically between 0.1 and 0.5 outputs are set to zero (`p=0.1` means 10% of outputs are set to zero).\n",
    "\n",
    "5) An activation layer. In this case ReLU (rectified linear unit). ReLU activation is most common for the inner layers of a neural network. Negative input values are set to zero. Positive input values are left unchanged.\n",
    "\n",
    "6) A second linear fully connected layer (again twice the number of input features). This is again followed by batch normalisation, dropout and ReLU activation layers.\n",
    "\n",
    "7) A final fully connected linear layer of two nodes (more nodes could be used for more classes).\n",
    "\n",
    "8) Apply sigmoid activation to convert each output node to range 0-1 output.\n",
    "\n",
    "The output of the net are two numbers (corresponding to scored for died/survived) between 0 and 1. These do not necessarily add up exactly to one (if Sigmoid is replaced with SoftMax then they will add up to 1, but here we will stick to sigmoid). The one with the highest value is taken as the classification result. This structure of neural net allows for any number of classes (e.g 10 classes for digit recognition).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, number_features):\n",
    "        # Define layers\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(number_features, number_features * 2)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(number_features * 2)\n",
    "        self.fc2 = torch.nn.Linear(number_features * 2, number_features * 2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(number_features * 2)\n",
    "        self.fc3 = torch.nn.Linear(number_features * 2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define sequence of layers\n",
    "        x = self.fc1(x) # Fully connected layer\n",
    "        x = self.bn1(x) # Batch normalisation\n",
    "        x = F.dropout(x, p=0.3) # Apply dropout\n",
    "        x = F.relu(x) # ReLU activation\n",
    "        x = self.fc2(x) # Fully connected layer\n",
    "        x = self.bn2(x) # Batch normalisation\n",
    "        x = F.dropout(x, p=0.3) # Apply dropout\n",
    "        x = F.relu(x) # ReLU activation\n",
    "        x = self.fc3(x) # Fully connected layer\n",
    "        x = torch.sigmoid(x) # Sigmoid output (0-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select device depedning on whether a GPU is available\n",
    "\n",
    "Thi smethod would also allow you to set a device manually, such as if you want to force CPU use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "# dev = \"cpu\"  # Force CPU use of wished (for small numebrs of features)\n",
    "\n",
    "device = torch.device(dev)  \n",
    "a = torch.zeros(4,3)    \n",
    "a = a.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_fold 1: 0.793\n",
      "K_fold 2: 0.803\n",
      "K_fold 3: 0.82\n",
      "K_fold 4: 0.798\n",
      "K_fold 5: 0.871\n"
     ]
    }
   ],
   "source": [
    "# Set up lists to hold results\n",
    "training_acc_results = []\n",
    "test_acc_results = []\n",
    "\n",
    "# Set up splits\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "k_counter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X_np, y_np):\n",
    "    k_counter +=1\n",
    "    print(f'K_fold {k_counter}:',end=' ')\n",
    "    \n",
    "    # Get X and Y train/test\n",
    "    X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "    \n",
    "    # Scale X data\n",
    "    X_train_sc, X_test_sc = scale_data(X_train, X_test)\n",
    "    \n",
    "    # Define network\n",
    "    number_features = X_train_sc.shape[1]        \n",
    "    net = Net(number_features)\n",
    "\n",
    "    # Set use of devise (GPU or CPU)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    ### Train model\n",
    "    # Note: Lots of these parameters may be fine tuned\n",
    "    \n",
    "    # Set batch size (cases per batch - commonly 8-64)\n",
    "    batch_size = 32\n",
    "    # Epochs (number of times to pass over data)\n",
    "    num_epochs = 200\n",
    "    # Learning rate (how much each bacth updates the model)\n",
    "    learning_rate = 0.003\n",
    "    # Calculate numebr of batches\n",
    "    batch_no = len(X_train_sc) // batch_size\n",
    "    \n",
    "    # Set up optimizer for classification\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train model by passing through the data the required number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Shuffle the training data\n",
    "        X_train_sc, y_train = shuffle(X_train_sc, y_train)\n",
    "\n",
    "        # Set net to training mode\n",
    "        net.train()\n",
    "\n",
    "        for i in range(batch_no):\n",
    "            \n",
    "            # Get X and y batch data\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            x_var = Variable(torch.FloatTensor(X_train_sc[start:end]))\n",
    "            y_var = Variable(torch.LongTensor(y_train[start:end]))\n",
    "\n",
    "            # Set use of devise (GPU or CPU)\n",
    "            x_var = x_var.to(device)\n",
    "            y_var = y_var.to(device)\n",
    "            \n",
    "            # These steps train the model: Forward + Backward + Optimize\n",
    "            optimizer.zero_grad() # reset optimizer\n",
    "            ypred_var = net(x_var) # predict y\n",
    "            loss = criterion(ypred_var, y_var) # Calculate loss\n",
    "            loss.backward() # Back propagate loss through network\n",
    "            optimizer.step() # Update network to reduce loss\n",
    "            \n",
    "    ### Test model (print results for each k-fold iteration)\n",
    "\n",
    "    # Set net to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Get training accuracy\n",
    "    test_var = Variable(torch.FloatTensor(X_train_sc))\n",
    "    test_var = test_var.to(device)\n",
    "    result = net(test_var)\n",
    "\n",
    "    values, labels = torch.max(result, 1)\n",
    "    y_pred_train = labels.cpu().data.numpy()\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    training_acc_results.append(accuracy_train)\n",
    " \n",
    "    # Get test accuracy\n",
    "    test_var = Variable(torch.FloatTensor(X_test_sc))\n",
    "    test_var = test_var.to(device)\n",
    "    result = net(test_var)\n",
    "\n",
    "    values, labels = torch.max(result, 1)\n",
    "    y_pred_test = labels.cpu().data.numpy()\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "    print(f'{accuracy_test:0.3}')\n",
    "    test_acc_results.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show training and test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8820224719101124,\n",
       " 0.8821879382889201,\n",
       " 0.879382889200561,\n",
       " 0.8695652173913043,\n",
       " 0.8681626928471248]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show individual accuracies on training data\n",
    "training_acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7932960893854749,\n",
       " 0.8033707865168539,\n",
       " 0.8202247191011236,\n",
       " 0.797752808988764,\n",
       " 0.8707865168539326]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show individual accuracies on test data\n",
    "test_acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876, 0.817\n"
     ]
    }
   ],
   "source": [
    "# Get mean results\n",
    "mean_training = np.mean(training_acc_results)\n",
    "mean_test = np.mean(test_acc_results)\n",
    "\n",
    "# Display each to three decimal places\n",
    "print (f'{mean_training:0.3f}, {mean_test:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results: Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up X data \n",
    "x_for_box = [training_acc_results, test_acc_results]\n",
    "\n",
    "# Set up X labels\n",
    "labels = ['Training', 'Test'] \n",
    "\n",
    "# Set up figure\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "# Add subplot (can be used to define multiple plots in same figure)\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Define Box Plot (`widths` is optional)\n",
    "ax1.boxplot(x_for_box, \n",
    "            widths=0.7,\n",
    "            whis=10)\n",
    "\n",
    "# Set X and Y labels\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('samuel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b368e36a85415766688ec72e3e874a4b525584eabf4bf7122952a4e0fd64fcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
